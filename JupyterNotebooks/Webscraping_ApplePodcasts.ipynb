{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a script for scraping **reviews** from the **Apple Podcast** website.\n",
        "\n",
        "First of all, you need to connect this Colab notebook with your Google Drive and define the directory for input and output data."
      ],
      "metadata": {
        "id": "VMM3wdd5TbHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "directory=\"/content/drive/My Drive/Colab_NLP_UM/\""
      ],
      "metadata": {
        "id": "v6wx6ArFTmAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to install additional packages. The most important package is the **App Store Scraper** for accessing reviews."
      ],
      "metadata": {
        "id": "dMdZGYkiUEBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## install packages that are not part of Python's standard distribution\n",
        "\n",
        "!pip install app_store_scraper "
      ],
      "metadata": {
        "id": "E4QxcXlaTmLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can import the packages and run the actual code. To scrape data from a specific podcast, we need to find the podcast name (cf. podcast URL) and the app id (also indicated in the pdocast ULR).\n",
        "\n",
        "Example of an Apple podcast URL used in this script: https://podcasts.apple.com/us/podcast/black-girl-gone-a-true-crime-podcast/id1556267741?see-all=reviews\n",
        "\n",
        "The reviews include the star-ratings, dates and reviewer names and are first of all written to the \"review\" column of a data frame."
      ],
      "metadata": {
        "id": "pPlnOwxkUST7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYybHd19TKzS"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "from app_store_scraper import AppStore\n",
        "\n",
        "# app_name = podcast name from URL\n",
        "# app_id = podcast id from URL\n",
        "\n",
        "podcast = AppStore(country='us', app_name='black-girl-gone-a-true-crime-podcast', app_id = '1556267741') \n",
        "\n",
        "podcast.review(how_many=7000) # change number if necessary\n",
        "\n",
        "reviews=podcast.reviews\n",
        "\n",
        "print(\"This podcast has \", len(reviews), \"reviews.\")\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# columns in each review = date, review, rating, isEdited, userName, title\n",
        "\n",
        "podcastdf = pd.DataFrame(np.array(podcast.reviews),columns=['review'])\n",
        "\n",
        "display(podcastdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can write the individual information from the dataframe to a CSV file on Google Drive for further processing."
      ],
      "metadata": {
        "id": "Zv2bCYiCSGj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = open(directory+'podcast_reviews.csv', 'w') # change file name for each podcast you scrape\n",
        "csv_writer = csv.writer(data_file)\n",
        "\n",
        "for x in range (0, len(reviews)):\n",
        "   p_dict = podcastdf.loc[[x]].values[0][0]\n",
        "   # print(p_dict) optional output to check performance\n",
        "   if x==0:\n",
        "       header = p_dict.keys()\n",
        "       csv_writer.writerow(header)\n",
        "       csv_writer.writerow(p_dict.values())\n",
        "   else:\n",
        "       csv_writer.writerow(p_dict.values())\n",
        "\n",
        "data_file.close()"
      ],
      "metadata": {
        "id": "nF0tY7t9RzVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script provided by Monika Barget, Maastricht University, March 2022"
      ],
      "metadata": {
        "id": "KtixB_xzVYNE"
      }
    }
  ]
}